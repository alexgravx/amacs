{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization TD1 - Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from div import div\n",
    "from grad import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    return np.loadtxt(filename)\n",
    "\n",
    "def display_image(image, title=\"Image\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"outputs/{title}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "# load image\n",
    "z = load_image(\"marie_degraded\")\n",
    "\n",
    "# image size\n",
    "K, L = z.shape\n",
    "print(f\"The image size is {K} x {L}\")\n",
    "\n",
    "# display image\n",
    "display_image(z, \"Marie Degraded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "\n",
    "# indices corresponding to tearing\n",
    "indJ = None  # TO BE COMPLETED\n",
    "print(f\"Tearing represents {100 * len(indJ) / (K * L)} % of the image\")\n",
    "\n",
    "# indices of complementary area\n",
    "indI = None  # TO BE COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_algorithm(z, nitm):\n",
    "    K, L = z.shape\n",
    "    xr = z.copy()\n",
    "    cost = []\n",
    "    for nit in range(nitm):\n",
    "        v, h = grad(xr)\n",
    "        xr = None  # TO BE COMPLETED\n",
    "        cost.append((np.linalg.norm(v, 'fro')**2 + np.linalg.norm(h, 'fro')**2) / 2)\n",
    "        print(f\"{nit+1} : cost={cost[-1]}\")\n",
    "    return xr, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "# gradient algorithm for minimizing g o L\n",
    "\n",
    "nitm = 15000 # maximum number of iterations\n",
    "beta = 8 # Lipshitz constant of the gradient\n",
    "gamma = 1.9 / beta # step-size of the algorithm\n",
    "xr, cost = gradient_algorithm(z, nitm, beta, gamma) # complete above function\n",
    "display_image(xr, \"Restored Image with Quadratic Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projball2(xr, z, rho, indI):\n",
    "    \"\"\"\n",
    "    Projection of xr onto the L2 ball || x(indI) - z(indI) || <= rho.\n",
    "\n",
    "    Parameters:\n",
    "    xr : ndarray (vector to be projected)\n",
    "    z : ndarray (center of the ball)\n",
    "    rho : float (radius of the ball)\n",
    "    indI : ndarray (indices of constrained components)\n",
    "\n",
    "    Returns:\n",
    "    p : ndarray (projected vector)\n",
    "    \"\"\"\n",
    "    p = xr.copy()\n",
    "\n",
    "    no = np.linalg.norm(xr[indI] - z[indI])\n",
    "\n",
    "    if no > rho:\n",
    "        p[indI] = None # TO BE COMPLETED\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_gradient_algorithm(z, nitm, rho, indI):\n",
    "    K, L = z.shape\n",
    "    xr = z.copy()\n",
    "    cost = []\n",
    "    for nit in range(nitm):\n",
    "        v, h = grad(xr)\n",
    "        xr = None  # TO BE COMPLETED\n",
    "        xr = projball2(xr, z, rho, indI)\n",
    "        cost.append((np.linalg.norm(v, 'fro')**2 + np.linalg.norm(h, 'fro')**2) / 2)\n",
    "        print(f\"{nit+1} : cost={cost[-1]}\")\n",
    "        if None:  # TO BE COMPLETED\n",
    "            break\n",
    "    return xr, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Questions 6-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 6-8\n",
    "# projected gradient algorithm for minimizing g o L subject to constraint\n",
    "nitm = 15000 # maximum number of iterations\n",
    "rho = 0.2 * np.sqrt(K * L)\n",
    "precc = 1e-7; # precision for stopping criterion\n",
    "xr, cost = projected_gradient_algorithm(z, nitm, beta, gamma, rho, indI)\n",
    "plt.figure(3)\n",
    "plt.subplot(121)\n",
    "display_image(xr, \"Restored Image with Constraint\")\n",
    "plt.subplot(122)\n",
    "plt.plot(cost)\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_gradient_algorithm_constraint(z, nitm):\n",
    "    xr = z.copy()\n",
    "    for nit in range(nitm):\n",
    "        break # TO BE COMPLETED\n",
    "    return xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 10 : projected gradient algorithm for minimizing smoothed total variation\n",
    "# subject to constraint\n",
    "\n",
    "eta = 5e-3 # smoothing parameter for total variation\n",
    "beta2 = None # TO BE COMPLETED # Lipshitz constant of the gradient\n",
    "gamma2 = 1.9 / beta2 # step-size of the algorithm\n",
    "xr = projected_gradient_algorithm_constraint(z, nitm, beta2, gamma2, eta)\n",
    "plt.figure(4)\n",
    "plt.subplot(121)\n",
    "display_image(xr, \"Restored Image with Smoothed TV\")\n",
    "plt.subplot(122)\n",
    "plt.plot(cost)\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerated_algorithm(z, nitm, beta2):\n",
    "    gamma3 = 1 / beta2\n",
    "    zeta = 2.05\n",
    "    xr = z.copy()\n",
    "    y = xr.copy()\n",
    "    cost = []\n",
    "    for nit in range(nitm):\n",
    "        v, h = grad(y)\n",
    "        div_vh = div(v, h)\n",
    "        x_next = y - gamma3 * div_vh\n",
    "        y = x_next + zeta * (x_next - xr)\n",
    "        xr = x_next\n",
    "        cost.append((np.linalg.norm(v, 'fro')**2 + np.linalg.norm(h, 'fro')**2) / 2)\n",
    "        print(f\"{nit+1} : cost={cost[-1]}\")\n",
    "    return xr, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 11 : accelerated algorithm\n",
    "\n",
    "gamma3 = 1 / beta2 # step-size of the algorithm\n",
    "zeta = 2.05 # inertia parameter\n",
    "xr_acc, cost_acc = accelerated_algorithm(z, nitm, beta2)\n",
    "plt.figure(5)\n",
    "plt.subplot(121)\n",
    "plt.imshow(xr_acc, cmap='gray')\n",
    "plt.title('Restored Image with Smoothed TV (Accelerated)')\n",
    "plt.subplot(122)\n",
    "plt.plot(cost_acc)\n",
    "plt.title('Convergence Plot with Acceleration')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
